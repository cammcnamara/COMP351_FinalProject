# -*- coding: utf-8 -*-
"""Comp 351 Final Project - Toxic Comment NLP

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ugB-hMmS3koBo0rCvOkCNlFVGluYmq0r

### COMP 351 Final Project - Toxic Comment Detection

##### Cameron McNamara, Bilal Adam, & Santiago Guerrero

https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge/data

# 1 - Installation + Setup
"""

!pip install gensim transformers tensorflow keras

# Core
import numpy as np
import pandas as pd

# Visualization
import matplotlib.pyplot as plt
import seaborn as sns

# Text Processing
import re
import string
import nltk
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer, WordNetLemmatizer
from sklearn.feature_extraction.text import TfidfVectorizer

# Classical ML Models
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC

# Deep Learning
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Dense, Conv1D, GlobalMaxPooling1D, Dropout, LSTM

from gensim.models import Word2Vec, KeyedVectors

# Transformer Models (BERT)
from transformers import BertTokenizer, TFBertModel, BertForSequenceClassification
from transformers import pipeline

#LLM (Llama)


import warnings
warnings.filterwarnings("ignore")

"""# ---------------------------------------------------------------------------------

# 2 - Dataset Import
"""

from google.colab import drive
drive.mount('/content/drive')
project_path = '/content/drive/MyDrive/COMP351_Final_Project'

train_df = pd.read_csv(f'{project_path}/train.csv')
test_df = pd.read_csv(f'{project_path}/test.csv')
test_labels_df = pd.read_csv(f'{project_path}/test_labels.csv')

"""# ---------------------------------------------------------------------------------

## 3 -  Pre-Processing/Cleaning
"""

import pandas as pd
import numpy as np
import re
import nltk
from nltk.corpus import stopwords
import spacy

## NLP Packages from Spacy
nlp = spacy.load("en_core_web_sm", disable=["parser", "ner", "textcat"])
nltk.download("stopwords")
stop_words = set(stopwords.words("english"))

##Remove NA, Dataset Should be clean, but for sanity sake
train_df = train_df.dropna(subset=["comment_text"])
train_df = train_df.drop_duplicates(subset=["comment_text"])
train_df.reset_index(drop=True, inplace=True)

## Clean Comments
train_df["clean_text"] = train_df["comment_text"].str.lower()
train_df["clean_text"] = train_df["clean_text"].apply(lambda x: re.sub(r"http\S+|www\S+|https\S+", "", x))
train_df["clean_text"] = train_df["clean_text"].apply(lambda x: re.sub(r"<.*?>", "", x))
train_df["clean_text"] = train_df["clean_text"].apply(lambda x: re.sub(r"[^a-zA-Z\s]", " ", x))

#Make sure alphabetic, remove stopwords, remove tiny tokens
train_df["clean_text"] = train_df["clean_text"].apply(
    lambda text: " ".join(
        [
            w for w in text.split()
            if w.isalpha()
            and w not in stop_words
            and len(w) > 1           #
        ]
    )
)

##Filter Out stop words + make sure word is alphabeltical
texts = train_df["clean_text"].tolist()
cleaned_texts = []

for text in texts:
    cleaned = " ".join([
        w for w in text.split()
        if w not in stop_words
        and w.isalpha()
        and len(w) > 1
    ])
    cleaned_texts.append(cleaned)

train_df["clean_text"] = cleaned_texts

"""# ---------------------------------------------------------------------------------

# 4 - Multi Class Logistic Regresssion

### 4.1 - Train
"""

label_cols = ["toxic", "severe_toxic", "obscene", "threat", "insult", "identity_hate"]

y = train_df[label_cols].values
train_df["any_toxic"] = train_df[label_cols].max(axis=1)
texts = train_df["clean_text"].values

X_train_text, X_val_text, y_train, y_val = train_test_split(
    texts,
    y,
    test_size=0.2, ## Validation
    random_state=42,
    stratify=train_df["any_toxic"]
)

## vectors for TF - IDF models, tokenization
from sklearn.feature_extraction.text import TfidfVectorizer

tfidf = TfidfVectorizer(
    max_features=100_000,   # can tweak
    stop_words='english',
    ngram_range=(1, 2)      # unigrams + bigrams
)

X_train_vec = tfidf.fit_transform(X_train_text)
X_val_vec   = tfidf.transform(X_val_text)

"""Note: x_train_vec and validation_vec will be used for all TF-IDF models (Logistic Regression and SVM)"""

from sklearn.linear_model import LogisticRegression
from sklearn.multiclass import OneVsRestClassifier

base_lr = LogisticRegression(
    max_iter=400,
    C=4.0,
    solver="liblinear"
)

clf = OneVsRestClassifier(base_lr)
clf.fit(X_train_vec, y_train)

from sklearn.metrics import roc_auc_score, classification_report

# Probabilities
y_val_proba = clf.predict_proba(X_val_vec)

# AUC per label
for i, label in enumerate(label_cols):
    auc = roc_auc_score(y_val[:, i], y_val_proba[:, i])
    print(f"{label}: AUC = {auc:.4f}")

# Turn probs into 0/1 with threshold 0.5
y_val_pred = (y_val_proba > 0.5).astype(int)

print(classification_report(y_val, y_val_pred, target_names=label_cols))

"""### 4.2 - Test"""

label_cols = ["toxic", "severe_toxic", "obscene", "threat", "insult", "identity_hate"]

# merge text + labels
test = test_df.merge(test_labels_df, on="id")

# convert -1 â†’ 0 (false), keep 1 as true
test[label_cols] = test[label_cols].replace(-1, 0)

# optional: any_toxic for equal splits
test["any_toxic"] = test[label_cols].max(axis=1)

"""#### Note: test df will be used for rest of models (merge between test.csv and test_labels.csv from dataset"""

## Perform Same pre processing steps on test data
test["clean_text"] = test["comment_text"].str.lower()
test["clean_text"] = test["clean_text"].apply(lambda x: re.sub(r"http\S+|www\S+|https\S+", "", x))
test["clean_text"] = test["clean_text"].apply(lambda x: re.sub(r"<.*?>", "", x))
test["clean_text"] = test["clean_text"].apply(lambda x: re.sub(r"[^a-zA-Z\s]", " ", x))

#Make sure alphabetic, remove stopwords, remove tiny tokens
test["clean_text"] = test["clean_text"].apply(
    lambda text: " ".join(
        [
            w for w in text.split()
            if w.isalpha()
            and w not in stop_words
            and len(w) > 1           #
        ]
    )
)

texts = test["clean_text"].tolist()
cleaned_texts = []

for text in texts:
    cleaned = " ".join([
        w for w in text.split()
        if w not in stop_words
        and w.isalpha()
        and len(w) > 1
    ])
    cleaned_texts.append(cleaned)

test["clean_text"] = cleaned_texts

"""Note: X_test_vec will be used for all TF-IDF models (Logistic Regression + SVM)

---


"""

X_test_vec = tfidf.transform(test["clean_text"])
y_test = test[label_cols].values

from sklearn.metrics import roc_auc_score, classification_report

# probability predictions
y_test_proba = clf.predict_proba(X_test_vec)

# AUC per label
for i, label in enumerate(label_cols):
    auc = roc_auc_score(y_test[:, i], y_test_proba[:, i])
    print(f"{label}: Test AUC = {auc:.4f}")

# convert to 0/1 using threshold 0.5
y_test_pred = (y_test_proba > 0.3).astype(int)

print(classification_report(y_test, y_test_pred, target_names=label_cols))

"""Results:

- toxic: Test AUC = 0.8874
- severe_toxic: Test AUC = 0.9709
- obscene: Test AUC = 0.9206
- threat: Test AUC = 0.9780
- insult: Test AUC = 0.9161
- identity_hate: Test AUC = 0.9610

# ---------------------------------------------------------------------------------

# 5 - Support Vector Machine
"""

from sklearn.svm import LinearSVC
from sklearn.multiclass import OneVsRestClassifier
from sklearn.metrics import roc_auc_score

base_svm = LinearSVC()

svm_clf = OneVsRestClassifier(base_svm)

"""#### 5.1 - Test"""

svm_clf.fit(X_train_vec, y_train)

y_val_scores = svm_clf.decision_function(X_val_vec)   # shape: (n_val, 6)

print("Validation AUCs (SVM):")
for i, label in enumerate(label_cols):
    auc = roc_auc_score(y_val[:, i], y_val_scores[:, i])
    print(f"{label}: Val AUC = {auc:.4f}")

"""#### 5.1 - Test"""

y_test_scores = svm_clf.decision_function(X_test_vec)

print("\nTest AUCs (SVM):")
for i, label in enumerate(label_cols):
    auc = roc_auc_score(y_test[:, i], y_test_scores[:, i])
    print(f"{label}: Test AUC = {auc:.4f}")

"""Test AUCs (SVM):
- toxic: Test AUC = 0.8854
- severe_toxic: Test AUC = 0.9603
- obscene: Test AUC = 0.9142
- threat: Test AUC = 0.9577
- insult: Test AUC = 0.9073
- identity_hate: Test AUC = 0.9481

# ---------------------------------------------------------------------------------

# 6 - Nueral Net Classifier

## 6.1 - Pre Process/ Tokenize (used for CNN too)
"""

#Define target variables
label_cols = ["toxic", "severe_toxic", "obscene", "threat", "insult", "identity_hate"]

y = train_df[label_cols].copy()
X = train_df["clean_text"]

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

vocab_size = 50000
tokenizer = Tokenizer(num_words=vocab_size, oov_token="<OOV>")

# fit on ALL training comments (labeled data only)
tokenizer.fit_on_texts(train_df["clean_text"])

train_sequences = tokenizer.texts_to_sequences(train_df["clean_text"])

max_len = 120

x_padded = pad_sequences(train_sequences, maxlen=max_len, padding='post', truncating='post')

# labels (multi-label matrix)
y = train_df[label_cols].values

from sklearn.model_selection import train_test_split

# y should be your (n_samples, 6) label matrix
label_cols = ["toxic", "severe_toxic", "obscene", "threat", "insult", "identity_hate"]
y = train_df[label_cols].values.astype("float32")

any_toxic = train_df["any_toxic"].values  # for stratify
max_len = x_padded.shape[1]               # should be 120

X_train, X_val, y_train, y_val = train_test_split(
    x_padded,
    y,
    test_size=0.2,
    random_state=42,
    stratify=any_toxic
)

print("X_train:", X_train.shape)
print("X_val:", X_val.shape)
print("y_train:", y_train.shape)
print("y_val:", y_val.shape)

from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout, SpatialDropout1D
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

vocab_size = min(tokenizer.num_words if tokenizer.num_words is not None else len(tokenizer.word_index) + 1,
                 len(tokenizer.word_index) + 1)

"""## 6.2 - Build"""

#Build Bidirectional LSTM NN
embedding_dim = 64
max_len = x_padded.shape[1]
vocab_size = min(50000, len(tokenizer.word_index) + 1)

model = Sequential([
    Embedding(
        input_dim=vocab_size,
        output_dim=embedding_dim,
        input_shape=(max_len,)
    ),
    SpatialDropout1D(0.2),
    Bidirectional(LSTM(64, return_sequences=False)), ## Bi Directional LSTM
    Dropout(0.3),
    Dense(64, activation="relu"),
    Dropout(0.3),
    Dense(y.shape[1], activation="sigmoid")  # 6 outputs
])

model.compile(
    loss="binary_crossentropy",
    optimizer="adam",
    metrics=[tf.keras.metrics.AUC(name="auc", multi_label=True)]
)

model.summary()

# padd test sequences
test_sequences = tokenizer.texts_to_sequences(test["clean_text"])
x_test_padded = pad_sequences(test_sequences, maxlen=x_padded.shape[1])

y_test = test[label_cols].values

"""## 6.3 - Train"""

from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

early_stop = EarlyStopping(
    monitor="val_auc",
    mode="max",
    patience=2,
    restore_best_weights=True
)

checkpoint = ModelCheckpoint(
    "best_lstm_model.keras",
    monitor="val_auc",
    mode="max",
    save_best_only=True,
    verbose=1
)

#train on smaller subset for time sake
X_train_small = X_train[:50000]
y_train_small = y_train[:50000]

history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    batch_size=128,
    epochs=5,
    callbacks=[early_stop, checkpoint],
    verbose=1
)

"""### 6.4 - Test"""

import numpy as np
from sklearn.metrics import roc_auc_score

# Probabilities from the model
y_test_proba_nn = model.predict(x_test_padded, batch_size=256)

for i, label in enumerate(label_cols):
    auc = roc_auc_score(y_test[:, i], y_test_proba_nn[:, i])
    print(f"{label}: Test AUC (BiLSTM) = {auc:.4f}")

"""First LTSM Model (3 epochs, 30k subset, 32 LTSM):
- toxic: Test AUC (BiLSTM) = 0.3602
- severe_toxic: Test AUC (BiLSTM) = 0.6289
- obscene: Test AUC (BiLSTM) = 0.4059
- threat: Test AUC (BiLSTM) = 0.4835
- insult: Test AUC (BiLSTM) = 0.4003
- identity_hate: Test AUC (BiLSTM) = 0.4568

----------------------------------------------------------------------------------------

# ---------------------------------------------------------------------------------

# 7 - CNN

#### 7.1 - Build (Same Tokenized data used from ANN)
"""

embedding_dim = 64
max_len = x_padded.shape[1]
vocab_size = min(50000, len(tokenizer.word_index) + 1)

n = 5
cnn_model = Sequential([
    Embedding(input_dim=vocab_size,output_dim=embedding_dim,input_shape=(max_len,)),# Embedding: converts token IDs -> dense vectors
    Conv1D(filters=128, kernel_size=n,activation="relu"),# 1D Convolution: learn n-gram patterns
    GlobalMaxPooling1D(),
    Dense(64, activation="relu"),
    Dropout(0.5),
    Dense(len(label_cols), activation="sigmoid")
])

cnn_model.compile(
    loss="binary_crossentropy",
    optimizer="adam",
    metrics=[tf.keras.metrics.AUC(name="auc", multi_label=True)]
)

cnn_model.summary()

# 3. Early stopping
early_stop_cnn = EarlyStopping(
    monitor="val_auc",
    mode="max",
    patience=2,
    restore_best_weights=True
)

"""#### 7.2 - Train"""

history_cnn = cnn_model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    batch_size=128,
    epochs=5,
    callbacks=[early_stop_cnn],
    verbose=1
)

"""#### 7.3 - Test"""

y_test_proba_cnn = cnn_model.predict(x_test_padded, batch_size=256)

for i, label in enumerate(label_cols):
    auc = roc_auc_score(y_test[:, i], y_test_proba_cnn[:, i])
    print(f"{label}: Test AUC (CNN) = {auc:.4f}")

"""Test Results CNN (5-fold, 5 Epochs)
- toxic: Test AUC (CNN) = 0.8384
- severe_toxic: Test AUC (CNN) = 0.9591
- obscene: Test AUC (CNN) = 0.8712
- threat: Test AUC (CNN) = 0.8907
- insult: Test AUC (CNN) = 0.8642
- identity_hate: Test AUC (CNN) = 0.8779

# ---------------------------------------------------------------------------------

# 8 - BERT - Bidirectional Encoder Representation from Transformers
"""

!pip install -q transformers accelerate

import numpy as np
import pandas as pd
import torch
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score
from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_linear_schedule_with_warmup

# Label columns
label_cols = ["toxic", "severe_toxic", "obscene", "threat", "insult", "identity_hate"]

# Training data
train_texts = train_df["clean_text"].fillna("").tolist()
y = train_df[label_cols].values.astype("float32")   # (n_train, 6)

# Test data (merged test_df + test_labels_df)
test_texts = test["clean_text"].fillna("").tolist()
y_test = test[label_cols].values.astype("float32")  # (n_test, 6)

# Train/val split
X_train_text, X_val_text, y_train, y_val = train_test_split(
    train_texts,
    y,
    test_size=0.2,
    random_state=42,
    stratify=train_df["any_toxic"]
)

print(len(X_train_text), len(X_val_text), y_train.shape, y_val.shape)

model_name = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_name)
max_length = 128  # good default for comments

class ToxicDataset(Dataset):
    def __init__(self, texts, labels, tokenizer, max_length):
        self.texts = texts
        self.labels = labels
        self.tokenizer = tokenizer
        self.max_length = max_length

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        text = str(self.texts[idx])
        label = self.labels[idx]

        enc = self.tokenizer(
            text,
            truncation=True,
            padding="max_length",
            max_length=self.max_length,
            return_tensors="pt"
        )

        return {
            "input_ids": enc["input_ids"].squeeze(0),
            "attention_mask": enc["attention_mask"].squeeze(0),
            "labels": torch.tensor(label, dtype=torch.float32)
        }

batch_size = 16  # keep small for BERT

train_subset_size = 10000  # you can lower or raise this
X_train_sub = X_train_text[:train_subset_size]
y_train_sub = y_train[:train_subset_size]

train_dataset = ToxicDataset(X_train_sub, y_train_sub, tokenizer, max_length)
val_dataset   = ToxicDataset(X_val_text, y_val, tokenizer, max_length)
test_dataset  = ToxicDataset(test_texts, y_test, tokenizer, max_length)

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

num_labels = len(label_cols)

bert_model = AutoModelForSequenceClassification.from_pretrained(
    model_name,
    num_labels=num_labels,
    problem_type="multi_label_classification"
)

bert_model.to(device)

epochs = 2
optimizer = torch.optim.AdamW(bert_model.parameters(), lr=5e-5)

total_steps = len(train_loader) * epochs
scheduler = get_linear_schedule_with_warmup(
    optimizer,
    num_warmup_steps=int(0.1 * total_steps),
    num_training_steps=total_steps
)

def train_one_epoch(model, dataloader, optimizer, scheduler, device):
    model.train()
    total_loss = 0.0

    for batch in dataloader:
        optimizer.zero_grad()

        input_ids = batch["input_ids"].to(device)
        attention_mask = batch["attention_mask"].to(device)
        labels = batch["labels"].to(device)

        outputs = model(
            input_ids=input_ids,
            attention_mask=attention_mask,
            labels=labels
        )
        loss = outputs.loss
        loss.backward()
        optimizer.step()
        scheduler.step()

        total_loss += loss.item()

    return total_loss / len(dataloader)

@torch.no_grad()
def eval_loss(model, dataloader, device):
    model.eval()
    total_loss = 0.0

    for batch in dataloader:
        input_ids = batch["input_ids"].to(device)
        attention_mask = batch["attention_mask"].to(device)
        labels = batch["labels"].to(device)

        outputs = model(
            input_ids=input_ids,
            attention_mask=attention_mask,
            labels=labels
        )
        loss = outputs.loss
        total_loss += loss.item()

    return total_loss / len(dataloader)

for epoch in range(epochs):
    train_loss = train_one_epoch(bert_model, train_loader, optimizer, scheduler, device)
    val_loss = eval_loss(bert_model, val_loader, device)
    print(f"Epoch {epoch+1}/{epochs} - Train loss: {train_loss:.4f} - Val loss: {val_loss:.4f}")

@torch.no_grad()
def get_logits_labels(model, dataloader, device):
    model.eval()
    all_logits = []
    all_labels = []

    for batch in dataloader:
        input_ids = batch["input_ids"].to(device)
        attention_mask = batch["attention_mask"].to(device)
        labels = batch["labels"].cpu().numpy()

        outputs = model(
            input_ids=input_ids,
            attention_mask=attention_mask
        )
        logits = outputs.logits.cpu().numpy()

        all_logits.append(logits)
        all_labels.append(labels)

    all_logits = np.vstack(all_logits)
    all_labels = np.vstack(all_labels)
    return all_logits, all_labels

test_logits, test_labels = get_logits_labels(bert_model, test_loader, device)

# Sigmoid to get probabilities
test_proba = 1 / (1 + np.exp(-test_logits))

# Overall macro AUC
macro_auc = roc_auc_score(test_labels, test_proba, average="macro")
print(f"Overall Macro Test AUC (BERT): {macro_auc:.4f}")

# Per-label AUC
for i, label in enumerate(label_cols):
    auc = roc_auc_score(test_labels[:, i], test_proba[:, i])
    print(f"{label}: Test AUC (BERT) = {auc:.4f}")

"""BERT Results (30 mins to run)
- Overall Macro Test AUC (BERT): 0.9425
- toxic: Test AUC (BERT) = 0.8932
- severe_toxic: Test AUC (BERT) = 0.9772
- obscene: Test AUC (BERT) = 0.9267
- threat: Test AUC (BERT) = 0.9631
- insult: Test AUC (BERT) = 0.9260
- identity_hate: Test AUC (BERT) = 0.9690

# Bonus/Data Processing - EDA
"""

#Explore + Save Comment Distribution by Toxicity type
toxic_columns = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']
print("Individual counts for each toxicity classification:")
total = 0;
toxic_counts_dict = {}
for col in toxic_columns:
    count_ones = train_df[col].sum()
    total += count_ones
    toxic_counts_dict[col] = count_ones
    print(f"{col}: {count_ones}")
print(f"TOTAL: {total}")
print("\nToxic classification counts dictionary:")
print(toxic_counts_dict)

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Define toxic_counts_dict with its previously computed values to avoid FileNotFoundError
toxic_counts_dict = {'toxic': 15294, 'severe_toxic': 1595, 'obscene': 8449, 'threat': 478, 'insult': 7877, 'identity_hate': 1405}

toxic_counts_series = pd.Series(toxic_counts_dict)

plt.figure(figsize=(10, 6))
sns.barplot(x=toxic_counts_series.index, y=toxic_counts_series.values, palette='viridis')
plt.title('Distribution of Toxicity Classifications in Training Data')
plt.xlabel('Toxicity Type')
plt.ylabel('Number of Comments')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

import pandas as pd
from google.colab import drive

# Re-mount Google Drive to ensure access to files
drive.mount('/content/drive')

# Re-define project_path and re-load train_df
project_path = '/content/drive/MyDrive/COMP351_Final_Project'
train_df = pd.read_csv(f'{project_path}/train.csv')

# Display the first few rows and shape of the re-loaded DataFrame to confirm successful loading
print("train_df loaded successfully. Shape:", train_df.shape)
print(train_df.head())

train_df['comment_length'] = train_df['comment_text'].apply(len)

print("Added 'comment_length' column to train_df. First 5 comments with their lengths:")
print(train_df[['comment_text', 'comment_length']].head())

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(12, 7))
sns.histplot(data=train_df, x='comment_length', hue='is_toxic', kde=True, bins=50, palette='coolwarm')
plt.title('Distribution of Comment Lengths for Toxic vs. Non-Toxic Comments')
plt.xlabel('Comment Length (Number of Characters)')
plt.ylabel('Number of Comments')
plt.legend(title='Is Toxic', labels=['Non-Toxic', 'Toxic'])
plt.tight_layout()
plt.show()

train_df["text_len"] = train_df["clean_text"].apply(lambda x: len(x.split()))
train_df["text_len"].describe(percentiles=[0.5, 0.75, 0.9, 0.95, 0.99])

"""# ---------------------------------------------------------------------------------

# Interactive Comment Classifier Models
"""

!pip install ipywidgets --quiet
from ipywidgets import Textarea, Button, VBox, Layout
from IPython.display import display, clear_output
import numpy as np

# If you're using LSTM/CNN:
from tensorflow.keras.preprocessing.sequence import pad_sequences

# If you're using BERT (PyTorch):
import torch

def clean_comment(text, stop_words):
    text = str(text).lower()
    tokens = text.split()
    cleaned_tokens = [
        w for w in tokens
        if w not in stop_words and w.isalpha() and len(w) > 1
    ]
    return " ".join(cleaned_tokens)

def classify_text_for_widget(text, threshold=0.3):
    cleaned = clean_comment(text, stop_words)
    X_vec = tfidf.transform([cleaned])

    print("Original comment:")
    print(text)
    print("\nCleaned:")
    print(cleaned)
    print("\nPredictions (threshold = {:.2f}):\n".format(threshold))

    # ---------------- Logistic Regression ----------------
    try:
        lr_proba = clf.predict_proba(X_vec)[0]            # shape (n_labels,)
        lr_preds = (lr_proba >= threshold).astype(int)

        print("=== Logistic Regression (TF-IDF) ===")
        for label, p, bit in zip(label_cols, lr_proba, lr_preds):
            status = "âœ…" if bit == 1 else "âŒ"
            print(f"  {label:13s}  p={p:.3f}  -> {status}")
        print()
    except NameError:
        pass

    # ---------------- SVM (LinearSVC) ----------------
    try:
        svm_scores = svm_clf.decision_function(X_vec)[0]  # shape (n_labels,)
        svm_proba = 1 / (1 + np.exp(-svm_scores))
        svm_preds = (svm_proba >= threshold).astype(int)

        print("=== SVM (TF-IDF, LinearSVC) ===")
        for label, p, bit in zip(label_cols, svm_proba, svm_preds):
            status = "âœ…" if bit == 1 else "âŒ"
            print(f"  {label:13s}  scoreâ‰ˆ{p:.3f}  -> {status}")
        print()
    except NameError:
        pass

    # Prepare sequence input for NN models (LSTM/CNN/etc.)
    try:
        seq = tokenizer.texts_to_sequences([cleaned])
        x_pad = pad_sequences(seq, maxlen=max_len)
    except NameError:
        x_pad = None

    # ---------------- BiLSTM / LSTM model ----------------
    try:
        if x_pad is not None:
            lstm_proba = lmodel.predict(x_pad, verbose=0)[0]
            lstm_preds = (lstm_proba >= threshold).astype(int)

            print("=== BiLSTM (Embeddings) ===")
            for label, p, bit in zip(label_cols, lstm_proba, lstm_preds):
                status = "âœ…" if bit == 1 else "âŒ"
                print(f"  {label:13s}  p={p:.3f}  -> {status}")
            print()
    except NameError:
        pass

    # ---------------- CNN model ----------------
    try:
        if x_pad is not None:
            cnn_proba = cnn_model.predict(x_pad, verbose=0)[0]
            cnn_preds = (cnn_proba >= threshold).astype(int)

            print("=== 1D CNN (Embeddings) ===")
            for label, p, bit in zip(label_cols, cnn_proba, cnn_preds):
                status = "âœ…" if bit == 1 else "âŒ"
                print(f"  {label:13s}  p={p:.3f}  -> {status}")
            print()
    except NameError:
        pass

    # ---------------- GloVe LSTM model (optional) ----------------
    try:
        if x_pad is not None:
            glove_proba = glove_model.predict(x_pad, verbose=0)[0]
            glove_preds = (glove_proba >= threshold).astype(int)

            print("=== BiLSTM (GloVe Embeddings) ===")
            for label, p, bit in zip(label_cols, glove_proba, glove_preds):
                status = "âœ…" if bit == 1 else "âŒ"
                print(f"  {label:13s}  p={p:.3f}  -> {status}")
            print()
    except NameError:
        pass

    # ---------------- BERT / DistilBERT (PyTorch) ----------------
    try:
        bert_model.eval()
        with torch.no_grad():
            enc = bert_tokenizer(
                cleaned,
                truncation=True,
                padding="max_length",
                max_length=128,
                return_tensors="pt"
            )
            input_ids = enc["input_ids"].to(device)
            attention_mask = enc["attention_mask"].to(device)

            outputs = bert_model(
                input_ids=input_ids,
                attention_mask=attention_mask
            )
            logits = outputs.logits.cpu().numpy()[0]
            bert_proba = 1 / (1 + np.exp(-logits))
            bert_preds = (bert_proba >= threshold).astype(int)

        print("=== BERT / DistilBERT ===")
        for label, p, bit in zip(label_cols, bert_proba, bert_preds):
            status = "âœ…" if bit == 1 else "âŒ"
            print(f"  {label:13s}  p={p:.3f}  -> {status}")
        print()
    except NameError:
        # bert_model or bert_tokenizer or device not defined
        pass


# ----- Widgets -----
text_box = Textarea(
    value="Type a comment hereâ€¦",
    placeholder="Type a comment hereâ€¦",
    description='Comment:',
    layout=Layout(width='100%', height='100px')
)

run_button = Button(description="Classify")

def on_button_clicked(b):
    clear_output(wait=True)
    display(ui)  # re-display the UI
    print()
    classify_text_for_widget(text_box.value, threshold=0.3)

run_button.on_click(on_button_clicked)

ui = VBox([text_box, run_button])
display(ui)



"""# ---------------------------------------------------------------------------------

# TODO: Gemnini Integration

### 1. Get and Store Your API Key

First, you need an API key. If you don't have one, create it in [Google AI Studio](https://aistudio.google.com/app/apikey). Once you have your key, store it securely in Colab's secrets manager (the 'ðŸ”‘' icon in the left panel). Name the secret `GOOGLE_API_KEY`.
"""

# Import the Python SDK
import google.generativeai as genai
# Used to securely store your API key
from google.colab import userdata

# Retrieve the API key from Colab's secrets manager
GOOGLE_API_KEY=userdata.get('AIzaSyBMLaA6vT6lC8-rQElqjSgqLyMVjfIHNTY')

# Configure the Generative AI SDK with your API key
genai.configure(api_key=GOOGLE_API_KEY)

"""### 2. Initialize the Gemini 2.5 Model

After configuring the SDK, you can initialize the Gemini 2.5 model. We'll use `gemini-2.5-flash-preview-04-17` for this example.
"""

# Initialize the Gemini API with the specified model
gemini_model = genai.GenerativeModel('gemini-2.5-flash-preview-04-17')

print("Gemini 2.5 model initialized successfully!")

"""### 3. Make an API Call (Example)

Now you can make API calls to generate content. Here's an example of generating a short poem:
"""

# Generate content using the Gemini model
response = gemini_model.generate_content('Write a short, uplifting poem about the sunrise.')

# Print the generated text
print(response.text)